Here are the code files used for our CLIP usage and experiments.

- The notebooks contains code used for the comparison between clip and resnext using imagenet label on random image chosen by us, and a second part on emotion detection.
- The python files were used for cleaning the data and testing the Zero-shot Prediction on the Oxford Buildings. (We can send you the cleaned dataset if you want to test it out by yourself, it takes one hour to zero-shot predict the whole dataset)

Gaston TENTILLIER
Paul FOTSO KAPTUE
Florian BORDES
